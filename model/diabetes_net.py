"""
MindSporeç³–å°¿ç—…é¢„æµ‹ç¥ç»ç½‘ç»œæ¨¡å‹
"""
import mindspore as ms
import mindspore.nn as nn
import mindspore.ops as ops
from mindspore import Tensor, dtype as mstype
from mindspore.common.initializer import Normal, Uniform
import numpy as np

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.model_config import ModelConfig

class DiabetesNet(nn.Cell):
    """ç³–å°¿ç—…é¢„æµ‹ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, config: ModelConfig = None):
        super(DiabetesNet, self).__init__()
        
        self.config = config or ModelConfig()
        
        # ç½‘ç»œæ¶æ„
        self.input_size = self.config.input_size
        self.hidden_sizes = self.config.hidden_sizes
        self.output_size = self.config.output_size
        self.dropout_rate = self.config.dropout_rate
        
        # æ„å»ºå±‚
        self.layers = nn.SequentialCell()
        
        # è¾“å…¥å±‚
        prev_size = self.input_size
        
        # éšè—å±‚
        for i, hidden_size in enumerate(self.hidden_sizes):
            # å…¨è¿æ¥å±‚
            self.layers.append(
                nn.Dense(
                    prev_size, 
                    hidden_size,
                    weight_init=Normal(0.02),
                    bias_init='zeros'
                )
            )
            
            # æ‰¹å½’ä¸€åŒ–
            self.layers.append(nn.BatchNorm1d(hidden_size))
            
            # æ¿€æ´»å‡½æ•°
            if self.config.activation == "relu":
                self.layers.append(nn.ReLU())
            elif self.config.activation == "sigmoid":
                self.layers.append(nn.Sigmoid())
            elif self.config.activation == "tanh":
                self.layers.append(nn.Tanh())
            else:
                self.layers.append(nn.ReLU())
            
            # Dropout
            self.layers.append(nn.Dropout(p=self.dropout_rate))
            
            prev_size = hidden_size
        
        # è¾“å‡ºå±‚
        self.output_layer = nn.Dense(
            prev_size, 
            self.output_size,
            weight_init=Normal(0.02),
            bias_init='zeros'
        )
        
        # è¾“å‡ºæ¿€æ´»å‡½æ•°
        self.sigmoid = nn.Sigmoid()
        
    def construct(self, x):
        """å‰å‘ä¼ æ’­"""
        # é€šè¿‡éšè—å±‚
        x = self.layers(x)
        
        # è¾“å‡ºå±‚
        x = self.output_layer(x)
        x = self.sigmoid(x)
        
        return x

class DiabetesLoss(nn.Cell):
    """ç³–å°¿ç—…é¢„æµ‹æŸå¤±å‡½æ•°"""
    
    def __init__(self, pos_weight: float = 1.0):
        super(DiabetesLoss, self).__init__()
        self.pos_weight = pos_weight
        self.binary_cross_entropy = nn.BCELoss(reduction='mean')
        
    def construct(self, predictions, targets):
        """è®¡ç®—åŠ æƒäºŒå…ƒäº¤å‰ç†µæŸå¤±"""
        # é‡å¡‘æ ‡ç­¾ç»´åº¦
        targets = targets.view(-1, 1)
        
        # è®¡ç®—æŸå¤±
        loss = self.binary_cross_entropy(predictions, targets)
        
        return loss

class DiabetesWithLoss(nn.Cell):
    """å¸¦æŸå¤±çš„ç½‘ç»œåŒ…è£…å™¨"""
    
    def __init__(self, network, loss_fn):
        super(DiabetesWithLoss, self).__init__()
        self.network = network
        self.loss_fn = loss_fn
        
    def construct(self, features, labels):
        """å‰å‘ä¼ æ’­å¹¶è®¡ç®—æŸå¤±"""
        predictions = self.network(features)
        loss = self.loss_fn(predictions, labels)
        return loss, predictions

class DiabetesMetrics:
    """ç³–å°¿ç—…é¢„æµ‹è¯„ä¼°æŒ‡æ ‡"""
    
    @staticmethod
    def accuracy(predictions: Tensor, targets: Tensor, threshold: float = 0.5) -> float:
        """è®¡ç®—å‡†ç¡®ç‡"""
        pred_labels = (predictions > threshold).astype(mstype.float32)
        targets = targets.view(-1, 1)
        correct = (pred_labels == targets).sum()
        total = targets.shape[0]
        return float(correct / total)
    
    @staticmethod
    def precision_recall_f1(predictions: Tensor, targets: Tensor, threshold: float = 0.5):
        """è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°"""
        pred_labels = (predictions > threshold).astype(mstype.float32).asnumpy().flatten()
        targets = targets.asnumpy().flatten()
        
        # è®¡ç®—æ··æ·†çŸ©é˜µå…ƒç´ 
        tp = np.sum((pred_labels == 1) & (targets == 1))
        fp = np.sum((pred_labels == 1) & (targets == 0))
        fn = np.sum((pred_labels == 0) & (targets == 1))
        tn = np.sum((pred_labels == 0) & (targets == 0))
        
        # è®¡ç®—æŒ‡æ ‡
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        
        return precision, recall, f1
    
    @staticmethod
    def compute_all_metrics(predictions: Tensor, targets: Tensor, threshold: float = 0.5):
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡"""
        accuracy = DiabetesMetrics.accuracy(predictions, targets, threshold)
        precision, recall, f1 = DiabetesMetrics.precision_recall_f1(predictions, targets, threshold)
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.best_loss = float('inf')
        self.counter = 0
        self.early_stop = False
        
    def __call__(self, val_loss: float):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            self.early_stop = True
            
        return self.early_stop

def create_model(config: ModelConfig = None) -> DiabetesNet:
    """åˆ›å»ºæ¨¡å‹çš„ä¾¿æ·å‡½æ•°"""
    if config is None:
        config = ModelConfig()
        
    model = DiabetesNet(config)
    return model

def create_loss_fn(pos_weight: float = 1.0) -> DiabetesLoss:
    """åˆ›å»ºæŸå¤±å‡½æ•°çš„ä¾¿æ·å‡½æ•°"""
    return DiabetesLoss(pos_weight)

def create_model_with_loss(config: ModelConfig = None, pos_weight: float = 1.0) -> DiabetesWithLoss:
    """åˆ›å»ºå¸¦æŸå¤±çš„æ¨¡å‹"""
    model = create_model(config)
    loss_fn = create_loss_fn(pos_weight)
    return DiabetesWithLoss(model, loss_fn)

def print_model_info(model: DiabetesNet):
    """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
    print("ğŸ§  MindSporeç³–å°¿ç—…é¢„æµ‹æ¨¡å‹")
    print("=" * 50)
    print(f"è¾“å…¥ç»´åº¦: {model.input_size}")
    print(f"éšè—å±‚å°ºå¯¸: {model.hidden_sizes}")
    print(f"è¾“å‡ºç»´åº¦: {model.output_size}")
    print(f"Dropoutç‡: {model.dropout_rate}")
    print(f"æ¿€æ´»å‡½æ•°: {model.config.activation}")
    
    # è®¡ç®—å‚æ•°æ•°é‡
    param_count = 0
    for param in model.trainable_params():
        param_count += param.size
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {param_count:,}")
    print("=" * 50)

def test_model():
    """æµ‹è¯•æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•MindSporeæ¨¡å‹...")
    
    config = ModelConfig()
    model = create_model(config)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print_model_info(model)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 16
    test_input = Tensor(np.random.randn(batch_size, config.input_size), mstype.float32)
    
    # å‰å‘ä¼ æ’­æµ‹è¯•
    print(f"æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    
    model.set_train(False)
    output = model(test_input)
    
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"è¾“å‡ºå€¼èŒƒå›´: [{float(output.min()):.4f}, {float(output.max()):.4f}]")
    
    # æµ‹è¯•æŸå¤±å‡½æ•°
    loss_fn = create_loss_fn()
    targets = Tensor(np.random.randint(0, 2, (batch_size, 1)), mstype.float32)
    loss = loss_fn(output, targets)
    print(f"æµ‹è¯•æŸå¤±: {float(loss):.4f}")
    
    # æµ‹è¯•æŒ‡æ ‡
    metrics = DiabetesMetrics.compute_all_metrics(output, targets)
    print("æµ‹è¯•æŒ‡æ ‡:", metrics)
    
    print("âœ… æ¨¡å‹æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    # è®¾ç½®MindSporeä¸Šä¸‹æ–‡
    ms.set_context(mode=ms.GRAPH_MODE, device_target="CPU")
    
    # è¿è¡Œæµ‹è¯•
    test_model() 